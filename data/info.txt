cmd:
conda activate speech-emotion
python -m src.baseline.model_cnn

---------------------------------------------------------------------------------------------------
Τι έχουμε χτίσει μέχρι τώρα

dataset_loader.py
→ Σκανάρει IEMOCAP, φτιάχνει λίστα samples με path / emotion / label.

iemocap_dataset.py
→ Παίρνει αυτά τα samples και για κάθε ένα:

φορτώνει το wav

βγάζει log-mel spectrogram

κάνει pad/cut στα 300 frames

επιστρέφει tensor + label.

dataloaders.py
→ Τυλίγει τα παραπάνω σε DataLoader για train/val/test με batches.

model_cnn.py
→ Ορίζει το CNN που δέχεται [B, 1, 128, 300] και βγάζει 5 κλάσεις.

train.py
→ Όλα μαζί:

φορτώνει samples

κάνει 70/15/15 split

φτιάχνει dataloaders

τρέχει training loop (3 epochs test run) πάνω σε GPU.


---------------------------------------------------------------------------------------------------
# 1. Train baseline CNN στο IEMOCAP
python src/train.py

# 2. Train DANN (IEMOCAP source + RAVDESS target)
python src/train_dann.py

# 3. Evaluate baseline CNN στο RAVDESS
python src/eval_ravdess_baseline.py

# 4. Evaluate DANN στο RAVDESS
python src/eval_ravdess_dann.py
